import 'dart:io';
import 'package:flutter_dotenv/flutter_dotenv.dart';
import 'package:google_generative_ai/google_generative_ai.dart';

/// üéØ OMR (Optical Mark Recognition) Detector
/// 
/// Usa Gemini Flash para detectar VISUALMENTE qu√© c√≠rculos est√°n pintados
/// en lugar de intentar hacer OCR del s√≠mbolo.
/// 
/// Ventajas:
/// - Detecta relleno vs vac√≠o con visi√≥n real
/// - No depende de OCR de caracteres
/// - Muy preciso con im√°genes claras
/// - Maneja variaciones de estilos (bol√≠grafo, marcador, etc)
class OMRDetectorService {
  static const String _modelName = 'gemini-2.5-flash';
  late final GenerativeModel _visionModel;

  OMRDetectorService() {
    final envKey = const String.fromEnvironment('GEMINI_API_KEY', defaultValue: '');
    final dotenvKey = dotenv.env['GEMINI_API_KEY'] ?? '';
    final resolvedKey = envKey.isNotEmpty ? envKey : dotenvKey;

    print("üéØ [OMR Init] Buscando GEMINI_API_KEY...");
    print("üéØ [OMR Init] Desde const environment: ${envKey.isEmpty ? 'NO' : 'S√ç'}");
    print("üéØ [OMR Init] Desde .env: ${dotenvKey.isEmpty ? 'NO' : 'S√ç'}");
    print("üéØ [OMR Init] Clave resuelta: ${resolvedKey.isEmpty ? 'VAC√çA ‚ùå' : 'V√ÅLIDA ‚úÖ'}");

    if (resolvedKey.isEmpty) {
      throw StateError(
        'GEMINI_API_KEY no configurada. Agrega tu clave en .env o usa --dart-define="GEMINI_API_KEY=tu_clave"',
      );
    }

    try {
      _visionModel = GenerativeModel(
        model: _modelName,
        apiKey: resolvedKey,
      );
      print("üéØ [OMR Init] ‚úÖ Modelo Gemini inicializado correctamente");
    } catch (e) {
      print("‚ùå [OMR Init] Error al inicializar Gemini: $e");
      rethrow;
    }
  }

  /// Detecta respuestas usando OMR (detecci√≥n visual de marcas)
  /// Retorna un Map con estructura: {'answers': [...], 'confidence': 0.0-1.0}
  Future<Map<String, dynamic>> detectAnswers(
    File imageFile,
    int questionCount,
  ) async {
    print("üéØ [OMR] Iniciando detecci√≥n OMR (Optical Mark Recognition)...");
    print("üéØ [OMR] Modelo: $_modelName");
    print("üéØ [OMR] Buscando: CUADRADOS PINTADOS (no c√≠rculos)");
    print("üéØ [OMR] Imagen: ${imageFile.path}");
    print("üéØ [OMR] Preguntas esperadas: $questionCount");

    try {
      // Leer la imagen
      final imageBytes = await imageFile.readAsBytes();

      // Prompt especializado en OMR
      final prompt = '''
Eres un detector de OMR (Optical Mark Recognition) especializado en ex√°menes con formato de cuadrados.

TAREA CR√çTICA: Analiza esta imagen de un examen y detecta qu√© CUADRADOS est√°n MARCADOS/PINTADOS/OSCUROS.

FORMATO ESPERADO del examen:
- Cada pregunta tiene 4 opciones
- Cada opci√≥n est√° en el formato: "A) ‚ñ° texto" o "A) [ ] texto"
- El CUADRADO es el s√≠mbolo que est√° al lado de la letra (A, B, C, D)
- Si el CUADRADO est√° PINTADO/OSCURO/RELLENO = opci√≥n seleccionada
- Si el CUADRADO est√° VAC√çO/BLANCO = opci√≥n no seleccionada

INSTRUCCIONES DE AN√ÅLISIS:
1. Localiza cada pregunta numerada
2. Para cada pregunta, identifica sus 4 opciones (A, B, C, D)
3. Busca VISUALMENTE qu√© CUADRADO est√° RELLENO/OSCURO/PINTADO
4. Asocia el CUADRADO relleno con la letra correspondiente (A, B, C o D)

IMPORTANTE:
- Est√°s buscando CUADRADOS (‚ñ° ‚ñ†), NO c√≠rculos
- Un CUADRADO RELLENO/OSCURO (‚ñ† o pintado) = respuesta seleccionada
- Un CUADRADO VAC√çO/BLANCO (‚ñ°) = respuesta no seleccionada
- Solo busca VISUALMENTE si est√° relleno. No uses OCR.
- El CUADRADO relleno debe estar directamente despu√©s de la letra (A), B), C), D))
- Ignora completamente el texto de la respuesta, solo importa qu√© CUADRADO est√° marcado
- Una pregunta puede tener SOLO UN CUADRADO marcado

FORMATO DE RESPUESTA:
Devuelve SOLO un JSON v√°lido con este estructura exacta, sin texto extra:
{
  "answers": [
    {"q": 1, "val": "B"},
    {"q": 2, "val": "A"},
    {"q": 3, "val": "C"}
  ]
}

ESPECIFICACIONES:
- q = n√∫mero de pregunta (1-$questionCount)
- val = letra de la opci√≥n con CUADRADO RELLENO (A, B, C o D)
- Solo incluye preguntas donde detectes CLARAMENTE un CUADRADO pintado/oscuro
- Si no est√°s 100% seguro, omite esa pregunta
- El JSON debe ser v√°lido y parseable

BUSCA ESPEC√çFICAMENTE CUADRADOS:
1. CUADRADO despu√©s de "A)" con relleno/oscuro = respuesta A
2. CUADRADO despu√©s de "B)" con relleno/oscuro = respuesta B
3. CUADRADO despu√©s de "C)" con relleno/oscuro = respuesta C
4. CUADRADO despu√©s de "D)" con relleno/oscuro = respuesta D

EJEMPLOS DE LO QUE BUSCAS:
- Correcto: "A) ‚ñ† Respuesta" (CUADRADO lleno/relleno/oscuro = MARCADO)
- Correcto: "B) ‚ñ† Respuesta" (CUADRADO lleno/relleno/oscuro = MARCADO)
- Incorrecto: "A) ‚ñ° Respuesta" (CUADRADO vac√≠o/blanco = NO MARCADO)
- Incorrecto: "C) ‚ñ° Respuesta" (CUADRADO vac√≠o/blanco = NO MARCADO)

‚ö†Ô∏è ATENCI√ìN: NO confundas:
- CUADRADOS con C√çRCULOS
- CUADRADOS VAC√çOS (‚ñ°) con CUADRADOS RELLENOS (‚ñ†)
- Las letras D y O con los CUADRADOS dibujados

Conc√©ntrate SOLO en detectar CUADRADOS (forma rectangular) que est√°n OSCUROS/RELLENOS.
''';


      print("üéØ [OMR] Enviando a Gemini Vision...");

      final response = await _visionModel.generateContent([
        Content.multi([
          TextPart(prompt),
          DataPart('image/jpeg', imageBytes),
        ])
      ]);

      final responseText = response.text ?? '';
      print("üéØ [OMR] Respuesta de Gemini:\n$responseText");

      // Parsear respuesta
      final answers = _parseOMRResponse(responseText, questionCount);

      print("üéØ [OMR] ‚úÖ Detectadas ${answers.length} respuestas");

      return {
        'answers': answers,
        'confidence': _estimateConfidence(answers, questionCount),
        'source': 'omr',
      };
    } catch (e) {
      print("‚ùå [OMR] Error: $e");
      return {'answers': [], 'confidence': 0.0, 'error': e.toString()};
    }
  }

  /// Parsea la respuesta JSON de Gemini
  List<Map<String, dynamic>> _parseOMRResponse(
    String responseText,
    int questionCount,
  ) {
    List<Map<String, dynamic>> answers = [];

    try {
      // Buscar JSON en la respuesta (puede haber texto extra)
      final jsonStart = responseText.indexOf('{');
      final jsonEnd = responseText.lastIndexOf('}');

      if (jsonStart < 0 || jsonEnd < 0) {
        print("‚ö†Ô∏è [OMR] No se encontr√≥ JSON en la respuesta");
        return answers;
      }

      final jsonStr = responseText.substring(jsonStart, jsonEnd + 1);
      print("üéØ [OMR] JSON extra√≠do: $jsonStr");

      // Parsear manualmente (sin dependencias)
      // Buscar patr√≥n: "q": N, "val": "X"
      // M√°s flexible: permite espacios variables
      final pattern = RegExp(r'"q"\s*:\s*(\d+)\s*,\s*"val"\s*:\s*"([A-D])"', multiLine: true);
      final matches = pattern.allMatches(jsonStr);

      if (matches.isEmpty) {
        print("‚ö†Ô∏è [OMR] No se encontraron respuestas en el patr√≥n esperado");
        return answers;
      }

      for (final match in matches) {
        try {
          final questionNum = int.parse(match.group(1)!);
          final answer = match.group(2)!;

          if (questionNum > 0 && questionNum <= questionCount) {
            answers.add({
              'q': questionNum,
              'val': answer,
            });
            print("üéØ [OMR] ‚úÖ P$questionNum: $answer");
          } else {
            print("‚ö†Ô∏è [OMR] Pregunta fuera de rango: P$questionNum (esperadas: 1-$questionCount)");
          }
        } catch (e) {
          print("‚ö†Ô∏è [OMR] Error al parsear match: ${match.group(0)} - Error: $e");
        }
      }

      print("üéØ [OMR] Total de respuestas extra√≠das: ${answers.length}/$questionCount");
      return answers;
    } catch (e) {
      print("‚ùå [OMR] Error cr√≠tico al parsear respuesta: $e");
      return answers;
    }
  }

  /// Estima el nivel de confianza basado en cobertura
  double _estimateConfidence(
    List<Map<String, dynamic>> answers,
    int questionCount,
  ) {
    if (answers.isEmpty) return 0.0;
    // Gemini 2.5 Flash tiene mejor precisi√≥n visual que 1.5 Flash
    // As√≠ que podemos confiar m√°s en los resultados
    final coverage = answers.length / questionCount;
    
    // Si detecta la mayor√≠a de preguntas, alta confianza (0.95)
    // Si detecta al menos 50%, confianza media-alta (0.85)
    // Menos del 50%, confianza media (0.70)
    if (coverage > 0.8) {
      return 0.95;
    } else if (coverage > 0.5) {
      return 0.85;
    } else {
      return 0.70;
    }
  }
}
